---
name: archivebox

services:
  archivebox:
    image: ghcr.io/archivebox/archivebox:0.7.3@sha256:fdf2936192aa1e909b0c3f286f60174efa24078555be4b6b90a07f2cef1d4909
    container_name: archivebox
    hostname: archivebox
    depends_on:
      - sonic
    env_file:
      - archivebox.env
    volumes:
      - data:/data
      # ./data/personas/Default/chrome_profile/Default:/data/personas/Default/chrome_profile/Default
    labels:
      - "de.panzer1119.docker.volume.default.cifs.host=op://Docker/ArchiveBox/CIFS/Host"
      - "de.panzer1119.docker.volume.default.cifs.username=op://Docker/ArchiveBox/CIFS/Username"
      - "de.panzer1119.docker.volume.default.cifs.password=op://Docker/ArchiveBox/CIFS/Password"
      - "de.panzer1119.docker.volume.archivebox_data.cifs.share=op://Docker/ArchiveBox/CIFS/Share_Data"
    ports:
      - "8024:8000"
    # For ad-blocking during archiving, uncomment this section and the pihole service below
    # networks:
    #   - dns
    dns:
      - 192.168.6.4
    restart: unless-stopped
    extends:
      file: ../../common/docker-compose.yml
      service: logging-gelf


  ######## Optional Addons: tweak examples below as needed for your specific use case ########

  ### This optional container runs scheduled jobs in the background (and retries failed ones). To add a new job:
  #   $ docker compose run archivebox schedule --add --every=day --depth=1 'https://example.com/some/rss/feed.xml'
  # then restart the scheduler container to apply any changes to the scheduled task list:
  #   $ docker compose restart archivebox_scheduler
  # https://github.com/ArchiveBox/ArchiveBox/wiki/Scheduled-Archiving

  #  archivebox_scheduler:
  #    image: ghcr.io/archivebox/archivebox:0.7.3
  #    container_name: archivebox_scheduler
  #    command: schedule --foreground --update --every=day
  #    environment:
  #      # - PUID=911                        # set to your host user's UID & GID if you encounter permissions issues
  #      # - PGID=911
  #      - TIMEOUT=120                       # use a higher timeout than the main container to give slow tasks more time when retrying
  #      - SEARCH_BACKEND_ENGINE=sonic       # tells ArchiveBox to use sonic container below for fast full-text search
  #      - SEARCH_BACKEND_HOST_NAME=sonic
  #      - SEARCH_BACKEND_PASSWORD=SomeSecretPassword
  #      # For other config it's better to set using `docker compose run archivebox config --set SOME_KEY=someval` instead of setting here
  #      # ...
  #      # For more info, see: https://github.com/ArchiveBox/ArchiveBox/wiki/Docker#configuration
  #    volumes:
  #      - data:/data
  #    # cpus: 2                               # uncomment / edit these values to limit scheduler container resource consumption
  #    # mem_limit: 2048m
  #    #    # restart: always
  #    restart: unless-stopped
  #    extends:
  #      file: ../../common/docker-compose.yml
  #      service: logging-gelf


  ### This runs the optional Sonic full-text search backend (much faster than default rg backend).
  # If Sonic is ever started after not running for a while, update its full-text index by running:
  #   $ docker-compose run archivebox update --index-only
  # https://github.com/ArchiveBox/ArchiveBox/wiki/Setting-up-Search

  sonic:
    image: archivebox/sonic:1.4.9@sha256:452064bfdab535fb8a6019937f1d753e0dfb2c94d2a87ebd166e2d556de78692
    container_name: archivebox_sonic
    env_file:
      - sonic.env
    volumes:
      #- ./sonic.cfg:/etc/sonic.cfg:ro    # mount to customize: https://raw.githubusercontent.com/ArchiveBox/ArchiveBox/stable/etc/sonic.cfg
      - /docker/data/archivebox-sonic:/var/lib/sonic/store
    expose:
      - 1491
    restart: unless-stopped
    extends:
      file: ../../common/docker-compose.yml
      service: logging-gelf


  ### This optional container runs xvfb+noVNC so you can watch the ArchiveBox browser as it archives things,
  # or remote control it to set up a chrome profile w/ login credentials for sites you want to archive.
  # https://github.com/ArchiveBox/ArchiveBox/wiki/Chromium-Install#setting-up-a-chromium-user-profile
  # https://github.com/ArchiveBox/ArchiveBox/wiki/Chromium-Install#docker-vnc-setup

  #  novnc:
  #    image: theasp/novnc:latest
  #    environment:
  #      - DISPLAY_WIDTH=1920
  #      - DISPLAY_HEIGHT=1080
  #      - RUN_XTERM=no
  #    ports:
  #      # to view/control ArchiveBox's browser, visit: http://127.0.0.1:8080/vnc.html
  #      # restricted to access from localhost by default because it has no authentication
  #      - "127.0.0.1:8080:8080"
  #    restart: unless-stopped
  #    extends:
  #      file: ../../common/docker-compose.yml
  #      service: logging-gelf


  ### Example: run all your ArchiveBox traffic through a WireGuard VPN tunnel to avoid IP blocks.
  # You can also use any other VPN that works at the docker/IP level, e.g. Tailscale, OpenVPN, etc.

  # wireguard:
  #   image: linuxserver/wireguard:latest
  #   network_mode: 'service:archivebox'
  #   cap_add:
  #     - NET_ADMIN
  #     - SYS_MODULE
  #   sysctls:
  #     - net.ipv4.conf.all.rp_filter=2
  #     - net.ipv4.conf.all.src_valid_mark=1
  #   volumes:
  #     - /lib/modules:/lib/modules
  #     - ./wireguard.conf:/config/wg0.conf:ro

  ### Example: Run ChangeDetection.io to watch for changes to websites, then trigger ArchiveBox to archive them
  # Documentation: https://github.com/dgtlmoon/changedetection.io
  # More info: https://github.com/dgtlmoon/changedetection.io/blob/master/docker-compose.yml

  #  changedetection:
  #    image: ghcr.io/dgtlmoon/changedetection.io
  #    volumes:
  #      - ./data-changedetection:/datastore
  #    restart: unless-stopped
  #    extends:
  #      file: ../../common/docker-compose.yml
  #      service: logging-gelf


  ### Example: Run PYWB in parallel and auto-import WARCs from ArchiveBox

  pywb:
    image: webrecorder/pywb:2.8.4@sha256:7455bfb6d6223da015faa2a5e4b2ae409e16252aff2fa518a35829e6ee846bf8
    container_name: archivebox_pywb
    #    entrypoint: /bin/sh -c '(wb-manager init default || test $$? -eq 2) && wb-manager add default /archivebox/archive/*/warc/*.warc.gz; wayback;'
    #    environment:
    #      - INIT_COLLECTION=archivebox
    volumes:
      - webarchive:/webarchive:ro
    labels:
      - "de.panzer1119.docker.volume.default.cifs.host=op://Docker/ArchiveBox/CIFS/Host"
      - "de.panzer1119.docker.volume.default.cifs.username=op://Docker/ArchiveBox/CIFS/Username"
      - "de.panzer1119.docker.volume.default.cifs.password=op://Docker/ArchiveBox/CIFS/Password"
      - "de.panzer1119.docker.volume.archivebox_webarchive.cifs.share=op://Docker/ArchiveBox/CIFS/Share_Webarchive"
    ports:
      - "8025:8080"
    restart: unless-stopped
    extends:
      file: ../../common/docker-compose.yml
      service: logging-gelf


#networks:
#  # network just used for pihole container to offer :53 dns resolving on fixed ip for archivebox container
#  dns:
#    ipam:
#      driver: default
#      config:
#        - subnet: 172.20.0.0/24


# HOW TO: Set up cloud storage for your ./data/archive (e.g. Amazon S3, Backblaze B2, Google Drive, OneDrive, SFTP, etc.)
#   https://github.com/ArchiveBox/ArchiveBox/wiki/Setting-Up-Storage
#
#   Follow the steps here to set up the Docker RClone Plugin https://rclone.org/docker/
#     $ docker plugin install rclone/docker-volume-rclone:amd64 --grant-all-permissions --alias rclone
#     $ nano /var/lib/docker-plugins/rclone/config/rclone.conf
#     [examplegdrive]
#     type = drive
#     scope = drive
#     drive_id = 1234567...
#     root_folder_id = 0Abcd...
#     token = {"access_token":...}

# volumes:
#     archive:
#         driver: rclone
#         driver_opts:
#             remote: 'examplegdrive:archivebox'
#             allow_other: 'true'
#             vfs_cache_mode: full
#             poll_interval: 0

volumes:
  data:
    name: archivebox_data
    # Because this is a cifs volume, and it needs credentials, it is created outside of this file
    external: true
  webarchive:
    name: archivebox_webarchive
    # Because this is a cifs volume, and it needs credentials, it is created outside of this file
    external: true
